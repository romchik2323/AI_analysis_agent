

import json
import sys
import os
import traceback
from pathlib import Path


try:
    from mcp.server import Server
    from mcp.server.stdio import stdio_server
    from mcp import types
    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False
    print("‚ö†Ô∏è  mcp –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: pip install mcp", file=sys.stderr)

import pandas as pd
sys.path.insert(0, str(Path(__file__).parent))

from churn_analyzer import UniversalChurnAnalyzer
from rag_engine import ChurnRAGEngine
from agent import ChurnAgent



_analyzer: UniversalChurnAnalyzer = None
_rag: ChurnRAGEngine = None
_agent: ChurnAgent = None


def get_analyzer() -> UniversalChurnAnalyzer:
    global _analyzer
    if _analyzer is None:
        _analyzer = UniversalChurnAnalyzer()
        
        try:
            _analyzer.load_model()
        except FileNotFoundError:
            pass
    return _analyzer


def get_rag() -> ChurnRAGEngine:
    global _rag
    if _rag is None:
        _rag = ChurnRAGEngine()
        _rag.initialize()
    return _rag


def get_agent() -> ChurnAgent:
    global _agent
    if _agent is None:
        _agent = ChurnAgent(provider="auto", use_rag=True)
    return _agent



TOOLS = [
    {
        "name": "analyze_churn_dataset",
        "description": (
            "–ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV-—Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤, –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è "
            "–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –æ–± –æ—Ç—Ç–æ–∫–µ: –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç—Ç–æ–∫–∞, —Ç–æ–ø-—Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞, "
            "–∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ (ROC-AUC, Accuracy), —Å–µ–≥–º–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏. "
            "–†–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±–æ–π –∏–Ω–¥—É—Å—Ç—Ä–∏–µ–π: —Ç–µ–ª–µ–∫–æ–º, –±–∞–Ω–∫–∏, SaaS, e-commerce."
        ),
        "inputSchema": {
            "type": "object",
            "properties": {
                "csv_path": {
                    "type": "string",
                    "description": "–ü—É—Ç—å –∫ CSV-—Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤"
                },
                "target_column": {
                    "type": "string",
                    "description": "–ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ (–æ—Ç—Ç–æ–∫). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 'auto' ‚Äî –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ",
                    "default": "auto"
                },
                "model_type": {
                    "type": "string",
                    "enum": ["random_forest", "gradient_boosting"],
                    "description": "–¢–∏–ø –º–æ–¥–µ–ª–∏ ML. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é random_forest",
                    "default": "random_forest"
                }
            },
            "required": ["csv_path"]
        }
    },
    {
        "name": "score_customers",
        "description": (
            "–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–∏—Å–∫ –æ—Ç—Ç–æ–∫–∞ –¥–ª—è —Å–ø–∏—Å–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤. "
            "–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç—Ç–æ–∫–∞ (0-100%) –∏ —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞ (LOW/MEDIUM/HIGH) "
            "–¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞. –¢—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏."
        ),
        "inputSchema": {
            "type": "object",
            "properties": {
                "customers": {
                    "type": "array",
                    "description": "–°–ø–∏—Å–æ–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ –≤–∏–¥–µ –º–∞—Å—Å–∏–≤–∞ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏",
                    "items": {"type": "object"}
                },
                "top_n": {
                    "type": "integer",
                    "description": "–í–µ—Ä–Ω—É—Ç—å —Ç–æ–ª—å–∫–æ —Ç–æ–ø-N –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —Ä–∏—Å–∫–æ–º",
                    "default": 10
                }
            },
            "required": ["customers"]
        }
    },
    {
        "name": "get_retention_strategy",
        "description": (
            "–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —É–¥–µ—Ä–∂–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM. "
            "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç RAG (–±–∞–∑—É –∑–Ω–∞–Ω–∏–π) –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ª—É—á—à–∏–º–∏ –ø—Ä–∞–∫—Ç–∏–∫–∞–º–∏. "
            "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Claude API –∏ –ª–æ–∫–∞–ª—å–Ω—ã–π Qwen2.5."
        ),
        "inputSchema": {
            "type": "object",
            "properties": {
                "segment_description": {
                    "type": "string",
                    "description": "–û–ø–∏—Å–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è"
                }
            },
            "required": ["segment_description"]
        }
    },
    {
        "name": "search_knowledge_base",
        "description": (
            "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –æ–± –æ—Ç—Ç–æ–∫–µ –∫–ª–∏–µ–Ω—Ç–æ–≤. "
            "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç E5-large —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤, "
            "–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –∞–Ω–∞–ª–∏–∑–æ–≤ –∏ –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫ —É–¥–µ—Ä–∂–∞–Ω–∏—è."
        ),
        "inputSchema": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)"
                },
                "top_k": {
                    "type": "integer",
                    "description": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
                    "default": 3
                }
            },
            "required": ["query"]
        }
    },
    {
        "name": "explain_customer_churn",
        "description": (
            "–û–±—ä—è—Å–Ω—è–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç—Ç–æ–∫–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ –Ω–∞ –ø–æ–Ω—è—Ç–Ω–æ–º —è–∑—ã–∫–µ. "
            "–£–∫–∞–∑—ã–≤–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–¥–µ—Ä–∂–∞–Ω–∏—é."
        ),
        "inputSchema": {
            "type": "object",
            "properties": {
                "customer_data": {
                    "type": "object",
                    "description": "–î–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–∞ –≤ –≤–∏–¥–µ —Å–ª–æ–≤–∞—Ä—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
                }
            },
            "required": ["customer_data"]
        }
    },
    {
        "name": "get_model_status",
        "description": "–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: –º–µ—Ç—Ä–∏–∫–∏, –ø—Ä–∏–∑–Ω–∞–∫–∏, –¥–∞—Ç–∞ –æ–±—É—á–µ–Ω–∏—è.",
        "inputSchema": {
            "type": "object",
            "properties": {}
        }
    }
]



def handle_analyze_churn_dataset(args: dict) -> str:
    csv_path = args["csv_path"]
    target_column = args.get("target_column", "auto")
    model_type = args.get("model_type", "random_forest")

    if not Path(csv_path).exists():
        return json.dumps({"error": f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}"}, ensure_ascii=False)

    analyzer = get_analyzer()
    analyzer.load_data(csv_path, target_column=target_column)
    report = analyzer.train(model_name=model_type)

    
    try:
        agent = get_agent()
        llm_analysis = agent.analyze_report(report)
    except Exception as e:
        llm_analysis = f"LLM-–∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}"

    result = {
        "status": "success",
        "report": {
            "total_customers": report.total_customers,
            "churned_customers": report.churned_customers,
            "churn_rate": f"{report.churn_rate}%",
            "model_accuracy": f"{report.model_accuracy}%",
            "roc_auc": report.roc_auc,
            "precision": f"{report.precision:.1%}",
            "recall": f"{report.recall:.1%}",
            "f1": f"{report.f1:.1%}",
            "top_factors": report.top_factors[:5],
            "high_risk_customers": report.high_risk_count,
            "high_risk_churn_rate": f"{report.high_risk_churn_rate}%",
            "recommendations": report.recommendations,
        },
        "llm_analysis": llm_analysis
    }
    return json.dumps(result, ensure_ascii=False, indent=2)


def handle_score_customers(args: dict) -> str:
    customers = args["customers"]
    top_n = args.get("top_n", 10)

    analyzer = get_analyzer()
    if analyzer.model is None:
        return json.dumps({"error": "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏—Ç–µ analyze_churn_dataset"})

    df = pd.DataFrame(customers)
    scored = analyzer.score_customers(df)

    result_records = scored.head(top_n)[
        [col for col in scored.columns if col not in ["churn_probability", "risk_level"]]
        + ["churn_probability", "risk_level"]
    ].to_dict(orient="records")

    
    for r in result_records:
        r["risk_level"] = str(r["risk_level"])

    return json.dumps({
        "status": "success",
        "total_scored": len(scored),
        "top_results": result_records
    }, ensure_ascii=False, indent=2)


def handle_get_retention_strategy(args: dict) -> str:
    segment_description = args["segment_description"]
    agent = get_agent()
    strategy = agent.generate_retention_strategy(segment_description)
    return json.dumps({
        "status": "success",
        "strategy": strategy
    }, ensure_ascii=False, indent=2)


def handle_search_knowledge_base(args: dict) -> str:
    query = args["query"]
    top_k = args.get("top_k", 3)
    rag = get_rag()
    results = rag.search(query, top_k=top_k)
    return json.dumps({
        "status": "success",
        "query": query,
        "results": results
    }, ensure_ascii=False, indent=2)


def handle_explain_customer_churn(args: dict) -> str:
    customer_data = args["customer_data"]
    analyzer = get_analyzer()

    if analyzer.model is None:
        return json.dumps({"error": "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞"})

    scored = analyzer.score_single(customer_data)
    churn_prob = scored["churn_probability"]

    agent = get_agent()
    explanation = agent.explain_customer(customer_data, churn_prob)

    return json.dumps({
        "status": "success",
        "churn_probability": churn_prob,
        "risk_level": scored["risk_level"],
        "explanation": explanation
    }, ensure_ascii=False, indent=2)


def handle_get_model_status(args: dict) -> str:
    analyzer = get_analyzer()
    if analyzer.model is None:
        return json.dumps({"status": "no_model", "message": "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞"})

    return json.dumps({
        "status": "ready",
        "feature_count": len(analyzer.feature_columns),
        "features": analyzer.feature_columns,
        "target_column": analyzer.target_column,
        "model_type": type(analyzer.model).__name__
    }, ensure_ascii=False, indent=2)


HANDLERS = {
    "analyze_churn_dataset": handle_analyze_churn_dataset,
    "score_customers": handle_score_customers,
    "get_retention_strategy": handle_get_retention_strategy,
    "search_knowledge_base": handle_search_knowledge_base,
    "explain_customer_churn": handle_explain_customer_churn,
    "get_model_status": handle_get_model_status,
}



if MCP_AVAILABLE:
    app = Server("churn-analyzer")

    @app.list_tools()
    async def list_tools():
        return [
            types.Tool(
                name=t["name"],
                description=t["description"],
                inputSchema=t["inputSchema"]
            )
            for t in TOOLS
        ]

    @app.call_tool()
    async def call_tool(name: str, arguments: dict):
        if name not in HANDLERS:
            return [types.TextContent(
                type="text",
                text=json.dumps({"error": f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {name}"})
            )]
        try:
            result = HANDLERS[name](arguments)
            return [types.TextContent(type="text", text=result)]
        except Exception as e:
            error_msg = json.dumps({
                "error": str(e),
                "traceback": traceback.format_exc()
            }, ensure_ascii=False)
            return [types.TextContent(type="text", text=error_msg)]

    async def main():
        async with stdio_server() as (read_stream, write_stream):
            await app.run(
                read_stream, write_stream,
                app.create_initialization_options()
            )

    if __name__ == "__main__":
        import asyncio
        print("üöÄ Churn Analysis MCP Server –∑–∞–ø—É—â–µ–Ω", file=sys.stderr)
        asyncio.run(main())

else:
    
    if __name__ == "__main__":
        print("MCP SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –¢–µ—Å—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –Ω–∞–ø—Ä—è–º—É—é:")
        print(handle_get_model_status({}))