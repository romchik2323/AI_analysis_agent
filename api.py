"""
FastAPI Backend ‚Äî REST API –¥–ª—è —Å–∏—Å—Ç–µ–º—ã —Å–∫–æ—Ä–∏–Ω–≥–∞ –æ—Ç—Ç–æ–∫–∞.
–≠–Ω–¥–ø–æ–∏–Ω—Ç—ã:
  POST /train          ‚Äî –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ CSV
  POST /score          ‚Äî —Å–∫–æ—Ä–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤
  POST /score/single   ‚Äî —Å–∫–æ—Ä–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
  POST /chat           ‚Äî —á–∞—Ç —Å LLM-–∞–≥–µ–Ω—Ç–æ–º
  GET  /health         ‚Äî —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–∞
  GET  /model/status   ‚Äî –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
  POST /knowledge/add  ‚Äî –¥–æ–±–∞–≤–∏—Ç—å –∑–Ω–∞–Ω–∏–µ –≤ RAG
  POST /knowledge/search ‚Äî –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π

–ó–∞–ø—É—Å–∫:
    uvicorn api:app --reload --port 8000
"""

import os
import sys
from pathlib import Path
from typing import Optional, Any
import json

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import pandas as pd
import uvicorn

sys.path.insert(0, str(Path(__file__).parent))

from churn_analyzer import UniversalChurnAnalyzer
from rag_engine import ChurnRAGEngine
from agent import ChurnAgent



app = FastAPI(
    title="Churn Analysis API",
    description=(
        "Universal Customer Churn Prediction API. "
        "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–µ–ª–µ–∫–æ–º, –±–∞–Ω–∫–∏, SaaS, e-commerce. "
        "LLM-–∞–≥–µ–Ω—Ç: Claude API + Qwen2.5 (Ollama). RAG –Ω–∞ E5-large."
    ),
    version="2.0.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)


_analyzer: Optional[UniversalChurnAnalyzer] = None
_agent: Optional[ChurnAgent] = None
_rag: Optional[ChurnRAGEngine] = None
_last_report = None


def get_analyzer() -> UniversalChurnAnalyzer:
    global _analyzer
    if _analyzer is None:
        _analyzer = UniversalChurnAnalyzer()
        try:
            _analyzer.load_model()
        except FileNotFoundError:
            pass
    return _analyzer


def get_agent() -> ChurnAgent:
    global _agent
    if _agent is None:
        provider = os.getenv("LLM_PROVIDER", "auto")
        ollama_model = os.getenv("OLLAMA_MODEL", "qwen2.5")
        _agent = ChurnAgent(provider=provider, ollama_model=ollama_model)
    return _agent


def get_rag() -> ChurnRAGEngine:
    global _rag
    if _rag is None:
        _rag = ChurnRAGEngine()
        _rag.initialize()
    return _rag



class TrainRequest(BaseModel):
    csv_path: str = Field(..., description="–ü—É—Ç—å –∫ CSV-—Ñ–∞–π–ª—É")
    target_column: str = Field("auto", description="–¶–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞")
    model_type: str = Field("random_forest", description="random_forest | gradient_boosting")
    use_llm_analysis: bool = Field(True, description="–ó–∞–ø—É—Å—Ç–∏—Ç—å LLM-–∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")


class ScoreRequest(BaseModel):
    customers: list[dict[str, Any]] = Field(..., description="–°–ø–∏—Å–æ–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤")
    top_n: int = Field(10, description="–í–µ—Ä–Ω—É—Ç—å —Ç–æ–ø-N –ø–æ —Ä–∏—Å–∫—É")
    explain_top: int = Field(0, description="–û–±—ä—è—Å–Ω–∏—Ç—å —Ç–æ–ø-N –∫–ª–∏–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ LLM")


class SingleScoreRequest(BaseModel):
    customer: dict[str, Any] = Field(..., description="–î–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–∞")
    explain: bool = Field(False, description="–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å LLM-–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ")


class ChatRequest(BaseModel):
    message: str = Field(..., description="–í–æ–ø—Ä–æ—Å –∫ –∞–≥–µ–Ω—Ç—É")
    reset: bool = Field(False, description="–°–±—Ä–æ—Å–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞")


class KnowledgeAddRequest(BaseModel):
    text: str = Field(..., description="–¢–µ–∫—Å—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π")
    metadata: dict = Field(default_factory=dict)


class KnowledgeSearchRequest(BaseModel):
    query: str = Field(..., description="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
    top_k: int = Field(3)


class RetentionStrategyRequest(BaseModel):
    segment_description: str = Field(..., description="–û–ø–∏—Å–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤")



@app.get("/health")
async def health():
    analyzer = get_analyzer()
    return {
        "status": "ok",
        "model_loaded": analyzer.model is not None,
        "rag_documents": len(get_rag().store),
        "version": "2.0.0"
    }


@app.get("/model/status")
async def model_status():
    analyzer = get_analyzer()
    if analyzer.model is None:
        return {"status": "no_model", "message": "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞"}
    return {
        "status": "ready",
        "features": analyzer.feature_columns,
        "feature_count": len(analyzer.feature_columns),
        "target_column": analyzer.target_column,
        "model_type": type(analyzer.model).__name__
    }


@app.post("/train")
async def train(request: TrainRequest, background_tasks: BackgroundTasks):
    global _last_report

    if not Path(request.csv_path).exists():
        raise HTTPException(404, f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {request.csv_path}")

    analyzer = get_analyzer()
    try:
        analyzer.load_data(request.csv_path, target_column=request.target_column)
        report = analyzer.train(model_name=request.model_type)
        _last_report = report
    except Exception as e:
        raise HTTPException(400, str(e))

    response_data = {
        "status": "success",
        "report": {
            "total_customers": report.total_customers,
            "churned_customers": report.churned_customers,
            "churn_rate": f"{report.churn_rate}%",
            "model_accuracy": f"{report.model_accuracy}%",
            "roc_auc": report.roc_auc,
            "top_factors": report.top_factors[:5],
            "high_risk_count": report.high_risk_count,
            "recommendations": report.recommendations,
        },
        "llm_analysis": None
    }

    if request.use_llm_analysis:
        try:
            agent = get_agent()
            response_data["llm_analysis"] = agent.analyze_report(report)
        except Exception as e:
            response_data["llm_analysis"] = f"LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}"

    return JSONResponse(content=response_data)


@app.post("/score")
async def score(request: ScoreRequest):
    analyzer = get_analyzer()
    if analyzer.model is None:
        raise HTTPException(400, "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –í—ã–∑–æ–≤–∏—Ç–µ /train —Å–Ω–∞—á–∞–ª–∞.")

    df = pd.DataFrame(request.customers)
    scored = analyzer.score_customers(df)

    results = []
    for _, row in scored.head(request.top_n).iterrows():
        record = row.to_dict()
        record["risk_level"] = str(record["risk_level"])
        results.append(record)

    
    if request.explain_top > 0:
        agent = get_agent()
        for i, record in enumerate(results[:request.explain_top]):
            try:
                customer_data = {k: v for k, v in record.items()
                                 if k not in ("churn_probability", "risk_level")}
                record["llm_explanation"] = agent.explain_customer(
                    customer_data, record["churn_probability"]
                )
            except Exception as e:
                record["llm_explanation"] = f"–û—à–∏–±–∫–∞: {e}"

    return {
        "status": "success",
        "total_scored": len(scored),
        "results": results
    }


@app.post("/score/single")
async def score_single(request: SingleScoreRequest):
    analyzer = get_analyzer()
    if analyzer.model is None:
        raise HTTPException(400, "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")

    scored = analyzer.score_single(request.customer)
    response = {"status": "success", **scored}

    if request.explain:
        try:
            agent = get_agent()
            response["explanation"] = agent.explain_customer(
                request.customer, scored["churn_probability"]
            )
        except Exception as e:
            response["explanation"] = f"–û—à–∏–±–∫–∞ LLM: {e}"

    return response


@app.post("/chat")
async def chat(request: ChatRequest):
    agent = get_agent()

    if request.reset:
        agent.reset_conversation()
        if _last_report:
            agent.current_report = _last_report

    try:
        response = agent.chat(request.message)
        return {
            "status": "success",
            "response": response,
            "history_length": len(agent.conversation_history)
        }
    except Exception as e:
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞: {e}")


@app.post("/retention-strategy")
async def retention_strategy(request: RetentionStrategyRequest):
    agent = get_agent()
    strategy = agent.generate_retention_strategy(request.segment_description)
    return {"status": "success", "strategy": strategy}


@app.post("/knowledge/add")
async def knowledge_add(request: KnowledgeAddRequest):
    rag = get_rag()
    rag.add_analysis(request.text, metadata=request.metadata)
    return {"status": "success", "total_documents": len(rag.store)}


@app.post("/knowledge/search")
async def knowledge_search(request: KnowledgeSearchRequest):
    rag = get_rag()
    results = rag.search(request.query, top_k=request.top_k)
    return {"status": "success", "query": request.query, "results": results}



if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    print(f"üöÄ Churn Analysis API –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:{port}")
    print(f"üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:{port}/docs")
    uvicorn.run("api:app", host="0.0.0.0", port=port, reload=True)
